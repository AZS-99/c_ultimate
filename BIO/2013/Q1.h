//
// Created by Adam Saher on 2022-12-29.
//

#ifndef C_Q1_H
#define C_Q1_H
/*
Two clocks, which show the time in hours and minutes using the 24-hour clock, are running at different speeds. Each
clock is an exact number of minutes per hour fast. Both clocks start showing the same time (00:00) and are checked
regularly every hour (starting after one hour) according to an accurate timekeeper. What time will the two clocks show
on the first occasion when they are checked and show the same time?

For example, suppose the first clock runs 1 minute fast (per hour) and the second clock runs 31 minutes fast (per hour).
• When the clocks are first checked after one hour, the first clock will show 01:01 and the second clock will show 01:31;
• When the clocks are checked after two hours, they will show 02:02 and 03:02;
• After 48 hours the clocks will both
 show 00:48.

Write a program which reads in a two integers, each between 0 and 50,000 inclusive, indicating the number of minutes
fast (per hour) of the first and second clock respectively.

You should output the time shown on the clocks when they first match. Both the hour and the minutes should be displayed
with two digits.

Full marks will be granted for a time-and-memory complexity of O(1). Programs of a complexity which exceeds
O(n) will NOT be marked.

Sample Input 1:
1 31
Output for Sample Input 1:
00:48

Sample Input 2:
18 18
Output for Sample Input 2:
01:18

Sample Input 3:
17 215
Output for Sample Input 3:
06:40

Sample Input 4:
5779 5864
Output for Sample Input 4:
19:12

Sample Input 5:
21923 26268
Output for Sample Input 5:
14:24
 */

class Q1 {

};


#endif //C_Q1_H
